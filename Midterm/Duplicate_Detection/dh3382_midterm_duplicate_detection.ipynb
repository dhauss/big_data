{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cc389aa-8eb4-4de4-8341-41badec5cb1e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\n",
      "Requirement already satisfied: datasketch in /local_disk0/.ephemeral_nfs/envs/pythonEnv-00e5b496-c015-43d6-be74-c13b500fbef6/lib/python3.9/site-packages (1.6.4)\n",
      "Requirement already satisfied: numpy>=1.11 in /databricks/python3/lib/python3.9/site-packages (from datasketch) (1.21.5)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /databricks/python3/lib/python3.9/site-packages (from datasketch) (1.7.3)\n",
      "Python interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "# run if datasketch not already installed\n",
    "# %pip install datasketch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bef99fbc-35c4-43f3-93e6-343bc7b3edb6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<h1 style=\"text-align: center;\">\n",
    "Duplicate Detection\n",
    "</h1>\n",
    "\n",
    "Assume I was reading news items in the HuffPost website (https://www.huffpost.com/) and last clicked on a news article about gun control in the USA. The next day, I return to this website and it decides to prioritize new items for me based on the last news item I read. Use the Minhash/LSH algorithm to find URL link, headline, category, and short description of the 5 most similar new item (based on the \"short_description\" field: \"Police reportedly used stun guns on at least two parents who arrived for their kids after reports of an armed man on a school campus.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db003604-e548-452c-b432-415a783f4d0f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, split, udf\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "from datasketch import MinHash\n",
    "\n",
    "spark = SparkSession.builder.appName(\"dh3382-midterm-duplicate-detection\").getOrCreate()\n",
    "\n",
    "HUFF_PATH = '/FileStore/tables/Huffpost.json'\n",
    "\n",
    "# description string to compare with all entries in Huffpost json\n",
    "DESC_COMP = 'Police reportedly used stun guns on at least two parents who arrived for their kids after reports of an armed man on a school campus.'\n",
    "\n",
    "# split DESC_COMP into array of strings for jaccard similarity processing\n",
    "DESC_COMP_STR_ARR = DESC_COMP.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "675b6c54-1d48-4682-a88d-9ea0e5d172af",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "I first define a UDF using datasketch's jaccard similarity estimation function. I decided to use the built in PySpark split function to convert the short descriptions into string arrays trusting that it would be more efficient than a custom implementation, so the jaccard UDF takes in column values that have already been converted into string arrays. Following datasketch documentation, I then create two MinHash objects, one for each string array to be compared, and encode each using the MinHash update function. I use a constant string variable, DESC_COMP_STR_ARR to compare each value to the description specified in the prompt (alternatively, I could have added a column to the huff_df where all values were DESC_COMP_STR_ARR and passed that value in to the jaccard UDF. This would have made for a more general usage version of my jaccard udf, but otherwise similar results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30568a1b-7447-4f3b-b429-564df0589d2c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# jaccard UDF, compare with DESC_COMP_STR_ARR to avoid having to create extra column with const values\n",
    "def jaccard(str_arr):\n",
    "    m1, m2 = MinHash(), MinHash()\n",
    "    for s in str_arr:\n",
    "        m1.update(s.encode('utf8') )\n",
    "    for s in DESC_COMP_STR_ARR:\n",
    "        m2.update(s.encode('utf8') )\n",
    "    \n",
    "    return m1.jaccard(m2)\n",
    "\n",
    "jaccard_udf = udf(lambda str_arr: jaccard(str_arr), FloatType() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "603d0e1d-f093-48fd-8c5e-75c626ea7061",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "I then read in the json file, filter out any columns not needed for the result, and convert the short_description column from strings to arrays of strings to I can pass it in to the jaccard UDF. I initially filtered out all null entries, as well, but found none so I removed the function. I create a jaccard_similarity column using the jaccard UDF which compares the short_description in each row to the string specified in the prompt and produces a jaccard similarity float. I persist this result because Databricks was throttling my account, and with a much larger dataset this would also allow for faster actions on the dataframe with the jaccard_similarity column. I filter out all results with a jaccard similarity less than 0.1 to heuristically optimize sorting, then sort the table in descending order of jaccard similarity and show the top 5 most similar articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "882694bd-e9b8-4e8f-816d-4910f4b72196",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "      <th>short_description</th>\n",
       "      <th>jaccard_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffpost.com/entry/parents-arreste...</td>\n",
       "      <td>Parents Arrested After Attempting To Grab Thei...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>[Police, reportedly, used, stun, guns, on, at,...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffpost.com/entry/south-africa-ba...</td>\n",
       "      <td>At Least 15 Killed In South Africa Bar Shooting</td>\n",
       "      <td>WORLD NEWS</td>\n",
       "      <td>[Police, say, they, are, investigating, report...</td>\n",
       "      <td>0.210938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/battles-r...</td>\n",
       "      <td>Battles Rage For Yemen's Aden, Dozens Of Civil...</td>\n",
       "      <td>THE WORLDPOST</td>\n",
       "      <td>[SANAA,, Yemen, (AP), â€•, Shiite, rebels, and, ...</td>\n",
       "      <td>0.210938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/financial...</td>\n",
       "      <td>Financial Advisors Are Biased, Study Finds</td>\n",
       "      <td>MONEY</td>\n",
       "      <td>[Based, on, his, research,, Kritzman,, who, te...</td>\n",
       "      <td>0.210938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/donald-tr...</td>\n",
       "      <td>Trump Reportedly Once Bragged About 'First-Rat...</td>\n",
       "      <td>POLITICS</td>\n",
       "      <td>[The, president,, who, has, been, accused, by,...</td>\n",
       "      <td>0.203125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>link</th>\n      <th>headline</th>\n      <th>category</th>\n      <th>short_description</th>\n      <th>jaccard_similarity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://www.huffpost.com/entry/parents-arreste...</td>\n      <td>Parents Arrested After Attempting To Grab Thei...</td>\n      <td>U.S. NEWS</td>\n      <td>[Police, reportedly, used, stun, guns, on, at,...</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://www.huffpost.com/entry/south-africa-ba...</td>\n      <td>At Least 15 Killed In South Africa Bar Shooting</td>\n      <td>WORLD NEWS</td>\n      <td>[Police, say, they, are, investigating, report...</td>\n      <td>0.210938</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://www.huffingtonpost.com/entry/battles-r...</td>\n      <td>Battles Rage For Yemen's Aden, Dozens Of Civil...</td>\n      <td>THE WORLDPOST</td>\n      <td>[SANAA,, Yemen, (AP), â€•, Shiite, rebels, and, ...</td>\n      <td>0.210938</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://www.huffingtonpost.com/entry/financial...</td>\n      <td>Financial Advisors Are Biased, Study Finds</td>\n      <td>MONEY</td>\n      <td>[Based, on, his, research,, Kritzman,, who, te...</td>\n      <td>0.210938</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://www.huffingtonpost.com/entry/donald-tr...</td>\n      <td>Trump Reportedly Once Bragged About 'First-Rat...</td>\n      <td>POLITICS</td>\n      <td>[The, president,, who, has, been, accused, by,...</td>\n      <td>0.203125</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read in json file\n",
    "huff_raw = spark.read.json(HUFF_PATH)\n",
    "\n",
    "# filter out unnecessary columns 'authors' and 'date', initially filtered for nulls as well but none were present in the dataset\n",
    "huff_df = huff_raw.select(col('link'), col('headline'), col('category'), col('short_description') )\n",
    "\n",
    "# convert 'short_description' values from string to array of strings for MinHash processing\n",
    "huff_df = huff_df.withColumn('short_description', split('short_description', ' +') )\n",
    "\n",
    "# add jaccard similarity column using jaccard UDF\n",
    "huff_df = huff_df.withColumn('jaccard_similarity', jaccard_udf(col('short_description') ) )\n",
    "\n",
    "# persist to avoid recalculating jaccard similarity on sort\n",
    "huff_df.persist()\n",
    "\n",
    "# filter out low similarity results before sorting to optimize\n",
    "huff_df = huff_df.filter(col('jaccard_similarity') > 0.1)\n",
    "\n",
    "# sort on jaccard similarity to find most similar articles\n",
    "duplicate_detection_res = huff_df.sort('jaccard_similarity', ascending=False)\n",
    "\n",
    "# show top 5 results\n",
    "duplicate_detection_res.toPandas().head(5)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "dh3382_midterm_duplicate_detection",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
