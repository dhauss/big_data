<h1 style="text-align: center;">
Duplicate Detection
</h1>

<i>Prompt</i>: Assume I was reading news items in the HuffPost website (https://www.huffpost.com/) and last clicked on a news article about gun control in the USA. The next day, I return to this website and it decides to prioritize new items for me based on the last news item I read. Use the Minhash/LSH algorithm to find URL link, headline, category, and short description of the 5 most similar new item (based on the "short_description" field: "Police reportedly used stun guns on at least two parents who arrived for their kids after reports of an armed man on a school campus." )

I first define a UDF using datasketch's jaccard similarity estimation function. I decided to use the built in PySpark split function to convert the short descriptions into string arrays trusting that it would be more efficient than a custom implementation, so the jaccard UDF takes in column values that have already been converted into string arrays. Following datasketch documentation, I then create two MinHash objects, one for each string array to be compared, and encode each using the MinHash update function. I use a constant string variable, DESC_COMP_STR_ARR to compare each value to the description specified in the prompt (alternatively, I could have added a column to the huff_df where all values were DESC_COMP_STR_ARR and passed that value in to the jaccard UDF. This would have made for a more general usage version of my jaccard udf, but otherwise similar results).

I then read in the json file, filter out any columns not needed for the result, and convert the short_description column from strings to arrays of strings to I can pass it in to the jaccard UDF. I initially filtered out all null entries, as well, but found none so I removed the function. I create a jaccard_similarity column using the jaccard UDF which compares the short_description in each row to the string specified in the prompt and produces a jaccard similarity float. I persist this result because Databricks was throttling my account, and with a much larger dataset this would also allow for faster actions on the dataframe with the jaccard_similarity column. I filter out all results with a jaccard similarity less than 0.1 to heuristically optimize sorting, then sort the table in descending order of jaccard similarity and show the top 5 most similar articles.